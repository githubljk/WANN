{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANN experiments on UCI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.constraints import MinMaxNorm\n",
    "\n",
    "sys.path.append(\"..\\\\wann\")\n",
    "from utils import superconduct, domain, BaggingModels, cross_val\n",
    "from uci_experiments import run_uci_experiments\n",
    "from methods import *\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 0  # possible values: 0, 1, 2, 3\n",
    "target = 2  # possible values: 0, 1, 2, 3\n",
    "\n",
    "N = 10   # Number of labeled target data\n",
    "\n",
    "data, X, y, cuts, split_col = superconduct()\n",
    "shape = X.shape[1]\n",
    "\n",
    "src_index = domain(data, cuts, split_col, source)\n",
    "tgt_index = domain(data, cuts, split_col, target)\n",
    "\n",
    "np.random.seed(0)\n",
    "tgt_train_index, tgt_test_index = train_test_split(tgt_index, train_size=N)\n",
    "train_index = np.concatenate((src_index, tgt_train_index))\n",
    "\n",
    "std_sc = StandardScaler()\n",
    "std_sc.fit(X[train_index])\n",
    "X = std_sc.transform(X)\n",
    "y = (y - y[train_index].mean()) / y[train_index].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(shape, activation=None, C=1, name=\"BaseModel\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                    kernel_constraint=MinMaxNorm(0, C),\n",
    "                    bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    model = Model(inputs, modeled, name=name)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def get_encoder(shape, C=1, name=\"encoder\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def get_task(shape, C=1, activation=None, name=\"task\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "base_estimator = BaggingModels(func=get_base_model,\n",
    "                               n_models=1,\n",
    "                               n_jobs=None,\n",
    "                               shape=shape,\n",
    "                               C=1,\n",
    "                               random_state=0)\n",
    "fit_params = dict(epochs=200,\n",
    "                  batch_size=1000,\n",
    "                  verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74806783\n",
      "Target score: 0.372\n"
     ]
    }
   ],
   "source": [
    "tgt_only = copy.deepcopy(base_estimator)\n",
    "tgt_only.fit(X[tgt_train_index], y[tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = tgt_only.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.501\n"
     ]
    }
   ],
   "source": [
    "src_only = copy.deepcopy(base_estimator)\n",
    "src_only.fit(X[src_index], y[src_index], **fit_params)\n",
    "\n",
    "y_pred = src_only.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.453\n"
     ]
    }
   ],
   "source": [
    "no_reweight = copy.deepcopy(base_estimator)\n",
    "no_reweight.fit(X[train_index], y[train_index], **fit_params)\n",
    "\n",
    "y_pred = no_reweight.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrAdaBoostR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv error of estimator 0: 0.731 (0.5977362335)\n",
      "cv error of estimator 1: 0.520 (0.3815219270)\n",
      "Binary search's goal not meeted! Value is set to be the available best!\n",
      "cv error of estimator 2: 0.097 (0.0577779100)\n",
      "cv error of estimator 3: 0.269 (0.1486271435)\n",
      "cv error of estimator 4: 0.246 (0.0922835162)\n",
      "cv error of estimator 5: 0.225 (0.0550980187)\n",
      "cv error of estimator 6: 0.214 (0.0412351541)\n",
      "cv error of estimator 7: 0.196 (0.0415873954)\n",
      "cv error of estimator 8: 0.200 (0.0585441933)\n",
      "cv error of estimator 9: 0.220 (0.0510511527)\n",
      "Target score: 0.700\n"
     ]
    }
   ],
   "source": [
    "tradaboost = TwoStageTrAdaBoostR2(func=get_base_model,\n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=1,\n",
    "                                  C=1,\n",
    "                                  random_state=0,\n",
    "                                  shape=X.shape[1])\n",
    "tradaboost.fit(X, y, [src_index, tgt_train_index], **fit_params)\n",
    "y_pred = tradaboost.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.589\n"
     ]
    }
   ],
   "source": [
    "dann = BaggingModels(DANN, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_encoder=get_encoder, get_task=get_task, lambda_=0.05)\n",
    "\n",
    "resize_tgt_ind = np.array([tgt_train_index[i%len(tgt_train_index)]\n",
    "                           for i in range(len(src_index))])\n",
    "\n",
    "dann.fit(X, y, index=[src_index, resize_tgt_ind, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = dann.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.298\n"
     ]
    }
   ],
   "source": [
    "wann = BaggingModels(WANN, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_base_model=get_base_model, C=1, C_w=0.1)\n",
    "\n",
    "wann.fit(X, y, index=[src_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = wann.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], \n",
    "                           y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Cw Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: param = 0.010 | score = 0.3518\n",
      "Cross Validation: param = 0.020 | score = 0.3098\n",
      "Cross Validation: param = 0.050 | score = 0.1774\n",
      "Cross Validation: param = 0.100 | score = 0.1622\n",
      "Cross Validation: param = 0.200 | score = 0.2018\n",
      "Cross Validation: param = 0.500 | score = 0.2319\n",
      "Cross Validation: param = 1.000 | score = 0.3209\n",
      "Best: param = 0.100 | score = 0.1622\n"
     ]
    }
   ],
   "source": [
    "cross_val(\"WANN\", X, y, src_index, None, tgt_train_index,\n",
    "          params=[0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1],\n",
    "          fit_params=fit_params, cv=5,\n",
    "          get_base_model=get_base_model, C=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment for method: WANN\n",
      "\n",
      "\n",
      "############# 0 #############\n",
      "--------- 1 ----------\n",
      "Target_score: 0.232\n",
      "--------- 2 ----------\n",
      "Target_score: 0.298\n",
      "--------- 3 ----------\n",
      "Target_score: 0.323\n",
      "############# 1 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.437\n",
      "--------- 2 ----------\n",
      "Target_score: 0.258\n",
      "--------- 3 ----------\n",
      "Target_score: 0.353\n",
      "############# 2 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.616\n",
      "--------- 1 ----------\n",
      "Target_score: 0.399\n",
      "--------- 3 ----------\n",
      "Target_score: 0.351\n",
      "############# 3 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.591\n",
      "--------- 1 ----------\n",
      "Target_score: 0.512\n",
      "--------- 2 ----------\n",
      "Target_score: 0.327\n"
     ]
    }
   ],
   "source": [
    "df = run_uci_experiments(method=\"WANN\",\n",
    "                         get_base_model=get_base_model,\n",
    "                         get_encoder=get_encoder,\n",
    "                         get_task=get_task,\n",
    "                         C=1,\n",
    "                         C_w=0.1,\n",
    "                         lambda_=0.1,\n",
    "                         sigma=0.1,\n",
    "                         epochs=200,\n",
    "                         batch_size=1000,\n",
    "                         n_models=1,\n",
    "                         n_jobs=None,\n",
    "                         n_target_labeled=10,\n",
    "                         random_state=0,\n",
    "                         save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch all experiments (all methods, 10 times)\n",
    "Uncomment cell below to launch experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ..\\wann\\uci_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wann",
   "language": "python",
   "name": "wann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
